{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SOL1archive/KoGrammar/blob/main/test-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKuwtSQ3za1x",
        "outputId": "5bc06792-7f5a-4119-c5b0-757dbc3522c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "  \n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "IN_COLAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R3-AX11zbae",
        "outputId": "333d3471-a858-4242-b47a-f4da16e16bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.4.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.22.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Looking in indexes: https://test.pypi.org/simple/, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.39.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install rouge_score\n",
        "!pip install torchmetrics\n",
        "!pip install --upgrade accelerate\n",
        "!pip install rouge\n",
        "!pip install accelerate\n",
        "!pip install -i https://test.pypi.org/simple/ bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-ODY5-1y_9N",
        "outputId": "08255466-3df4-4370-8bb1-8288f8741b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJUrv8M7zWoC"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import timeit\n",
        "import datetime\n",
        "import os\n",
        "import gc\n",
        "from collections import namedtuple\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorboard\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR, CyclicLR\n",
        "import torchmetrics\n",
        "from torchsummary import summary\n",
        "\n",
        "from datasets import load_dataset, load_from_disk, concatenate_datasets, DatasetDict, Dataset\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import BartConfig, T5Config\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import evaluate\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge import Rouge\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09uLIuyOzfF3",
        "outputId": "09adbe29-0841-44ce-cfa0-550ab60cac66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4xva5WxzWoH"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset_path = 'drive/MyDrive/projects/KoGrammar/data/gogamza-kobart-base-v2_tokenized_dataset'\n",
        "baseline_checkpoint_path = 'drive/MyDrive/projects/KoGrammar/models/230510-16_32'\n",
        "distil_checkpoint_path = 'drive/MyDrive/projects/KoGrammar/models/small_model_230517-19_30'\n",
        "tiny_distil_checkpoint_path = 'drive/MyDrive/projects/KoGrammar/models/distil_tiny_230518-06_28'\n",
        "quantized_distil_checkpoint_path = 'drive/MyDrive/projects/KoGrammar/models/small_model_230517-19_30-quantized'\n",
        "quantized_tiny_distil_checkpoint_path = 'drive/MyDrive/projects/KoGrammar/models/distil_tiny_230518-06_28-quantized'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VmOJgtZ31DD",
        "outputId": "50840892-a238-4c6c-b317-e156e074a088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
          ]
        }
      ],
      "source": [
        "baseline_config = BartConfig.from_json_file(baseline_checkpoint_path + '/config.json')\n",
        "distil_config = BartConfig.from_json_file(distil_checkpoint_path + '/config.json')\n",
        "tiny_distil_config = BartConfig.from_json_file(tiny_distil_checkpoint_path + '/config.json')\n",
        "quantized_distil_config = BartConfig.from_json_file(quantized_distil_checkpoint_path + '/config.json')\n",
        "quantized_tiny_distil_config = BartConfig.from_json_file(quantized_tiny_distil_checkpoint_path + '/config.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQQxFuvNzWoI"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv6SafrLzWoJ",
        "outputId": "bbecb712-ef45-4396-b871-4ba55a5f1041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 1016426\n",
            "    })\n",
            "    train_baseline: Dataset({\n",
            "        features: ['__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 508213\n",
            "    })\n",
            "    train_distil: Dataset({\n",
            "        features: ['__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 508212\n",
            "    })\n",
            "    valid: Dataset({\n",
            "        features: ['__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 56468\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 56469\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(tokenized_dataset_path):\n",
        "    tokenized_dataset = load_from_disk(tokenized_dataset_path)\n",
        "    print(tokenized_dataset)\n",
        "else:\n",
        "    print(\"Tokenized dataset not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sY17dqbzWoK"
      },
      "source": [
        "## Baseline Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lCs4cwqzWoO",
        "outputId": "f6694577-e8d1-4f1a-e40c-078342f8b091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at drive/MyDrive/projects/KoGrammar/models/small_model_230517-19_30 and are newly initialized: ['model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.k_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at drive/MyDrive/projects/KoGrammar/models/distil_tiny_230518-06_28 and are newly initialized: ['model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.k_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('drive/MyDrive/projects/KoGrammar/models/230510-16_32')\n",
        "\n",
        "baseline_model = AutoModelForSeq2SeqLM.from_pretrained(baseline_checkpoint_path).to(device)\n",
        "distil_model = AutoModelForSeq2SeqLM.from_pretrained(distil_checkpoint_path).to(device)\n",
        "tiny_distil_model = AutoModelForSeq2SeqLM.from_pretrained(tiny_distil_checkpoint_path).to(device)\n",
        "\n",
        "_ = baseline_model.eval(), distil_model.eval(), tiny_distil_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_distil_model = AutoModelForSeq2SeqLM.from_pretrained(quantized_distil_checkpoint_path, load_in_8bit=True, device_map='auto')\n",
        "quantized_tiny_distil_model = AutoModelForSeq2SeqLM.from_pretrained(quantized_tiny_distil_checkpoint_path, load_in_8bit=True, device_map='auto')\n",
        "\n",
        "_ = quantized_distil_model.eval(), quantized_tiny_distil_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br-X5K1QfL-A",
        "outputId": "605e3c47-219a-4327-919a-5ef2aacbc728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
            "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` attribute will be overwritten with the one you passed to `from_pretrained`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
            "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` attribute will be overwritten with the one you passed to `from_pretrained`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXetGmiHzWoP",
        "outputId": "7e2c3c9b-2f23-4e71-e62c-6609010fc718"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 1\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "testset = tokenized_dataset['test'].shuffle()\n",
        "test_sample = testset.shuffle().select(range(1))\n",
        "test_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQXsYZDCzWoP"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, tokenizer, input):\n",
        "    generated_ids = model.generate(**input)\n",
        "    generated_text = tokenizer.decode(generated_ids.squeeze(0), skip_special_tokens=True)\n",
        "    \n",
        "    return generated_text\n",
        "\n",
        "def generate_input_target(model, tokenizer, input, label):\n",
        "    input_text = tokenizer.decode(input['input_ids'].squeeze(0), skip_special_tokens=True)\n",
        "    generated_text = generate_seq(model, tokenizer, input)\n",
        "    target_text = tokenizer.decode(label.squeeze(0), skip_special_tokens=True)\n",
        "    \n",
        "    return {\n",
        "        'input_text': input_text,\n",
        "        'generated_text': generated_text, \n",
        "        'target_text': target_text\n",
        "    }\n",
        "\n",
        "def generate_from_data(model, tokenizer, data):\n",
        "    label = data['labels']\n",
        "    input_data = dict()\n",
        "    input_data['input_ids'] = data['input_ids']\n",
        "    input_data['attention_mask'] = data['attention_mask']\n",
        "\n",
        "    return generate_input_target(model, tokenizer, input_data, label)\n",
        "\n",
        "def eval(model, tokenizer, input_seq, label, metric, options = dict()):\n",
        "    generated_input_target = generate_input_target(model, tokenizer, input_seq, label)\n",
        "    score = metric.compute(\n",
        "        generated_input_target['generated_text'], \n",
        "        generated_input_target['target_text'],\n",
        "        **options\n",
        "    )\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGfsXiuRzWoQ",
        "outputId": "47d09b6b-3c57-48a3-d47d-adceb18ecebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ\n",
            "\n",
            "baseline: ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ\n",
            "\n",
            "distil: ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ\n",
            "\n",
            "tiny_distil: ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ\n",
            "\n",
            "quantized_distil: \n",
            "\n",
            "quantized_tiny_distil: \n",
            "\n",
            "ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ\n"
          ]
        }
      ],
      "source": [
        "testset = tokenized_dataset['test'].with_format(\"torch\", device=device)\n",
        "test_sample = testset.shuffle().select(range(1))\n",
        "output = generate_from_data(baseline_model, tokenizer, test_sample)\n",
        "\n",
        "input_data = dict()\n",
        "input_data['input_ids'] = test_sample['input_ids']\n",
        "input_data['attention_mask'] = test_sample['attention_mask']\n",
        "distil_output = generate_seq(distil_model, tokenizer, input_data)\n",
        "tiny_distil_output = generate_seq(tiny_distil_model, tokenizer, input_data)\n",
        "quantized_distil_output = generate_seq(quantized_distil_model, tokenizer, input_data)\n",
        "quantized_tiny_distil_output = generate_seq(quantized_tiny_distil_model, tokenizer, input_data)\n",
        "\n",
        "print(output['input_text'], \n",
        "      'baseline: ' + output['generated_text'], \n",
        "      'distil: ' + distil_output,\n",
        "      'tiny_distil: ' + tiny_distil_output,\n",
        "      'quantized_distil: ' + quantized_distil_output,\n",
        "      'quantized_tiny_distil: ' + quantized_tiny_distil_output,\n",
        "      output['target_text'], \n",
        "      sep='\\n\\n'\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-X7a1npzWoR",
        "outputId": "164347a6-50a1-48ba-a2ae-ddb099aff34c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [05:58<00:00,  5.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU: 0.7788133735457531\tROUGE: 0.5502721033933605\tTime: 343.32936048699867\tMean Time: 0.17552625791768847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [05:46<00:00,  5.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU: 0.7854816860026788\tROUGE: 0.5425506501322703\tTime: 331.4697660039874\tMean Time: 0.16946307055418577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [05:37<00:00,  5.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU: 0.8022218305572155\tROUGE: 0.564976884227559\tTime: 323.1128355939827\tMean Time: 0.1651062011210949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "bleu = evaluate.load('google_bleu')\n",
        "rouge = Rouge()\n",
        "result_df_dict = dict()\n",
        "model_lt = [\n",
        "    ('distil', distil_model), \n",
        "    ('tiny_distil', tiny_distil_model), \n",
        "    ('baseline', baseline_model), \n",
        "    #('quantized_distil', quantized_distil_model), \n",
        "    #('quantized_tiny_distil', quantized_tiny_distil_model),\n",
        "]\n",
        "\n",
        "performance_dict = dict()\n",
        "\n",
        "for name, model in model_lt:\n",
        "    accuracy_lt = []\n",
        "    bleu_score_lt = []\n",
        "    rouge_score_lt = []\n",
        "    time_score_lt = []\n",
        "\n",
        "    test_sample = testset.shuffle().select(range(2000))\n",
        "    total_time = 0\n",
        "    for example in tqdm(test_sample):\n",
        "        data = dict()\n",
        "        for key in example:\n",
        "            data[key] = example[key].unsqueeze(0)\n",
        "        start = timeit.default_timer()\n",
        "        output = generate_from_data(model, tokenizer, data)\n",
        "        end = timeit.default_timer()\n",
        "        generated_text = output['generated_text']\n",
        "        target_text = output['target_text']\n",
        "\n",
        "        try:\n",
        "            #accuracy_score = accuracy.compute(predictions=generated_text, references=target_text, tokenizer=tokenizer)\n",
        "            #bleu_score = bleu.compute(predictions=generated_text, references=target_text, tokenizer=tokenizer)\n",
        "            bleu_score = sentence_bleu([target_text], generated_text, smoothing_function=SmoothingFunction().method1)\n",
        "            rouge_score = rouge.get_scores(generated_text, target_text)[0]['rouge-2']['f']\n",
        "            #rouge_score = rouge.compute(predictions=generated_text, references=target_text)\n",
        "        except ValueError:\n",
        "            continue\n",
        "        \n",
        "        total_time += end - start\n",
        "        #accuracy_lt.append(accuracy_score)\n",
        "        bleu_score_lt.append(bleu_score)\n",
        "        rouge_score_lt.append(rouge_score)\n",
        "        time_score_lt.append(end - start)\n",
        "\n",
        "    bleu_score_series = pd.Series(bleu_score_lt)\n",
        "    rouge_score_series = pd.Series(rouge_score_lt)\n",
        "    time_score_series = pd.Series(time_score_lt)\n",
        "    print('BLEU: ' + str(bleu_score_series.mean()), \n",
        "          'ROUGE: ' + str(rouge_score_series.mean()), \n",
        "          'Time: ' + str(total_time), \n",
        "          'Mean Time: ' + str(time_score_series.mean()), \n",
        "          sep='\\t'\n",
        "          )\n",
        "    result_df = pd.concat([bleu_score_series, rouge_score_series, time_score_series], axis=1)\n",
        "    result_df.columns = ['BLEU-2', 'ROUGE-2 F1', 'Mean Time']\n",
        "    result_df_dict[name] = result_df\n",
        "    performance_dict[name] = total_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxKA-uq7zWoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71eade34-48d8-4265-ddb3-76c9fa3a3dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "distil:\t123859968\n",
            "tiny_distil:\t123859968\n",
            "baseline:\t123859968\n"
          ]
        }
      ],
      "source": [
        "for name, model in model_lt:\n",
        "    num = sum(p.numel() for p in model.model.parameters())\n",
        "\n",
        "    print(name + ':', num, sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWoEPuRVMoo2"
      },
      "outputs": [],
      "source": [
        "result_df_dict['distil']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrHUq00ENKK_"
      },
      "outputs": [],
      "source": [
        "result_df_dict['baseline']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50OUgJ2yNYVy"
      },
      "outputs": [],
      "source": [
        "result_df_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6e-_i67zWoT"
      },
      "outputs": [],
      "source": [
        "for name, result_df in result_df_dict.items():\n",
        "    print(name)\n",
        "    result_df.to_json(f'drive/MyDrive/projects/KoGrammar/result-data/{name}-test-result.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmCE6lRhzWoT"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 5), ncols=3, nrows=1)\n",
        "for i, (name, result_df) in enumerate(result_df_dict.items()):\n",
        "    sns.kdeplot(data=result_df, \n",
        "                fill=True, \n",
        "                palette=\"crest\", \n",
        "                common_grid=True, \n",
        "                cut=1, \n",
        "                ax=ax[i],\n",
        "                )\n",
        "    \n",
        "    ax[i].set_title(name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}