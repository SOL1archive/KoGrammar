{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SOL1archive/KoGrammar/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKuwtSQ3za1x",
        "outputId": "093554e6-ece7-4cf1-cfb8-be47c1ca6774"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "  \n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "IN_COLAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R3-AX11zbae",
        "outputId": "d8205c5b-e32f-43e1-9dd0-354bb010b9f5"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    !pip install transformers\n",
        "    !pip install datasets\n",
        "    !pip install evaluate\n",
        "    !pip install rouge_score\n",
        "    !pip install torchmetrics\n",
        "    !pip install --upgrade accelerate\n",
        "    !pip install rouge\n",
        "    !pip install accelerate\n",
        "    !pip install -i https://test.pypi.org/simple/ bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DJUrv8M7zWoC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-27 17:36:22.791599: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-27 17:36:23.658627: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/wsl/lib:\n",
            "2023-05-27 17:36:23.658719: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/wsl/lib:\n",
            "2023-05-27 17:36:23.658726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import timeit\n",
        "import datetime\n",
        "import os\n",
        "import gc\n",
        "from collections import namedtuple\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorboard\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR, CyclicLR\n",
        "import torchmetrics\n",
        "\n",
        "from datasets import load_dataset, load_from_disk, concatenate_datasets, DatasetDict, Dataset\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import BartConfig, T5Config\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from transformers import pipeline\n",
        "import evaluate\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge import Rouge\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09uLIuyOzfF3",
        "outputId": "a53c7a6c-f6b8-4063-bbf2-7304f2cd7b7d"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B4xva5WxzWoH"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset_path = './data/gogamza-kobart-base-v2_tokenized_dataset'\n",
        "baseline_checkpoint_path = './models/230510-16_32'\n",
        "distil_checkpoint_path = './models/small_model_230517-19_30'\n",
        "tiny_distil_checkpoint_path = './models/distil_tiny_230518-06_28'\n",
        "quantized_distil_checkpoint_path = './models/small_model_230517-19_30-quantized'\n",
        "quantized_tiny_distil_checkpoint_path = './models/distil_tiny_230518-06_28-quantized'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "-VmOJgtZ31DD",
        "outputId": "0191ef4e-674a-42d8-e794-70cd3fbe8c0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
          ]
        }
      ],
      "source": [
        "baseline_config = BartConfig.from_json_file(baseline_checkpoint_path + '/config.json')\n",
        "distil_config = BartConfig.from_json_file(distil_checkpoint_path + '/config.json')\n",
        "tiny_distil_config = BartConfig.from_json_file(tiny_distil_checkpoint_path + '/config.json')\n",
        "quantized_distil_config = BartConfig.from_json_file(quantized_distil_checkpoint_path + '/config.json')\n",
        "quantized_tiny_distil_config = BartConfig.from_json_file(quantized_tiny_distil_checkpoint_path + '/config.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nQQxFuvNzWoI"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv6SafrLzWoJ",
        "outputId": "8f46ec0b-ad55-4106-fa7e-553b400cab59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized dataset not found\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(tokenized_dataset_path):\n",
        "    tokenized_dataset = load_from_disk(tokenized_dataset_path)\n",
        "    print(tokenized_dataset)\n",
        "else:\n",
        "    print(\"Tokenized dataset not found\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2sY17dqbzWoK"
      },
      "source": [
        "## Baseline Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lCs4cwqzWoO",
        "outputId": "77265981-feae-40ec-d605-f52a670b44f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at ./models/small_model_230517-19_30 and are newly initialized: ['model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
            "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` attribute will be overwritten with the one you passed to `from_pretrained`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /home/thesol1/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda120.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
            "CUDA SETUP: Detected CUDA version 120\n",
            "CUDA SETUP: Loading binary /home/thesol1/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda120.so...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at ./models/distil_tiny_230518-06_28 and are newly initialized: ['model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
            "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` attribute will be overwritten with the one you passed to `from_pretrained`.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(baseline_checkpoint_path)\n",
        "baseline_model = AutoModelForSeq2SeqLM.from_pretrained(baseline_checkpoint_path)\n",
        "distil_model = AutoModelForSeq2SeqLM.from_pretrained(distil_checkpoint_path)\n",
        "quantized_distil_model = AutoModelForSeq2SeqLM.from_pretrained(quantized_distil_checkpoint_path, load_in_8bit=True, device_map='auto')\n",
        "tiny_distil_model = AutoModelForSeq2SeqLM.from_pretrained(tiny_distil_checkpoint_path)\n",
        "quantized_tiny_distil_model = AutoModelForSeq2SeqLM.from_pretrained(quantized_tiny_distil_checkpoint_path, load_in_8bit=True, device_map='auto')\n",
        "\n",
        "_ = baseline_model.eval(), distil_model.eval(), tiny_distil_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXetGmiHzWoP",
        "outputId": "225538b9-e67d-4983-a28e-0e8232a2156c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_1040/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3149916875.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_1040/3149916875.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'tokenized_dataset'</span> is not defined\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_1040/\u001b[0m\u001b[1;33m3149916875.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_1040/3149916875.py'\u001b[0m                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'tokenized_dataset'\u001b[0m is not defined\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testset = tokenized_dataset['test'].shuffle()\n",
        "test_sample = testset.shuffle().select(range(1))\n",
        "test_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rQXsYZDCzWoP"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, tokenizer, input):\n",
        "    generated_ids = model.generate(**input)\n",
        "    generated_text = tokenizer.decode(generated_ids.squeeze(0), skip_special_tokens=True)\n",
        "    \n",
        "    return generated_text\n",
        "\n",
        "def generate_input_target(model, tokenizer, input, label):\n",
        "    input_text = tokenizer.decode(input['input_ids'].squeeze(0), skip_special_tokens=True)\n",
        "    generated_text = generate_seq(model, tokenizer, input)\n",
        "    target_text = tokenizer.decode(label.squeeze(0), skip_special_tokens=True)\n",
        "    \n",
        "    return {\n",
        "        'input_text': input_text,\n",
        "        'generated_text': generated_text, \n",
        "        'target_text': target_text\n",
        "    }\n",
        "\n",
        "def generate_from_data(model, tokenizer, data):\n",
        "    label = data['labels']\n",
        "    input_data = dict()\n",
        "    input_data['input_ids'] = data['input_ids']\n",
        "    input_data['attention_mask'] = data['attention_mask']\n",
        "\n",
        "    return generate_input_target(model, tokenizer, input_data, label)\n",
        "\n",
        "def eval(model, tokenizer, input_seq, label, metric, options = dict()):\n",
        "    generated_input_target = generate_input_target(model, tokenizer, input_seq, label)\n",
        "    score = metric.compute(\n",
        "        generated_input_target['generated_text'], \n",
        "        generated_input_target['target_text'],\n",
        "        **options\n",
        "    )\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_pipe = pipeline('text2text-generation', model=baseline_model, tokenizer=tokenizer)\n",
        "distil_pipe = pipeline('text2text-generation', model=distil_model, tokenizer=tokenizer)\n",
        "tiny_distil_pipe = pipeline('text2text-generation', model=tiny_distil_model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "나는 문정이 좋아.\n",
            "나는 문정과가 좋아. \n"
          ]
        }
      ],
      "source": [
        "text = '나는문정과가조아'\n",
        "for pipe in [baseline_pipe, distil_pipe]:\n",
        "    result = pipe(text)\n",
        "    print(result[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_lt = [\n",
        "    '나는문정과가조아',\n",
        "    '나 완전 뚱떙이같아 오오',\n",
        "    '연세대는잡대다',\n",
        "    '이게게임이냐',\n",
        "    '7월에군머가는흑우있나',\n",
        "]\n",
        "text_lt2 = [\n",
        "    'ㄴㅏ는 ㄱㅏ끔 눈물을흘린다',\n",
        "    'ㅇㅣ게 ㄱㅔ임이냐',\n",
        "]\n",
        "\n",
        "text_lt += text_lt2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "원문: 나는문정과가조아\n",
            "baseline:\t나는 문정이 좋아.\n",
            "distil model:\t나는 문정과가 좋아. \n",
            "tiny distil:\t나는 문정가 좋아.\n",
            "--------------------------------------------------\n",
            "원문: 나 완전 뚱떙이같아 오오\n",
            "baseline:\t나 완전 뚱땡이 같아. 오오,\n",
            "distil model:\t나 완전 뚱땡이 같아. 오오. \n",
            "tiny distil:\t나 완전 뚱땡이 같아요.\n",
            "--------------------------------------------------\n",
            "원문: 연세대는잡대다\n",
            "baseline:\t연세대는 잡대다.\n",
            "distil model:\t연세대는 잡대다. \n",
            "tiny distil:\t연세대는 잡대다.\n",
            "--------------------------------------------------\n",
            "원문: 이게게임이냐\n",
            "baseline:\t이게 게임이냐?\n",
            "distil model:\t이게 게임이냐? \n",
            "tiny distil:\t이게 게임이냐?\n",
            "--------------------------------------------------\n",
            "원문: 7월에군머가는흑우있나\n",
            "baseline:\t7월에 군대 가는 흑우 있나?\n",
            "distil model:\t7월에 군 머가는 흑우 있나? \n",
            "tiny distil:\t7월에군머가는 흑우 있나?\n",
            "--------------------------------------------------\n",
            "원문: ㄴㅏ는 ㄱㅏ끔 눈물을흘린다\n",
            "baseline:\t나는 가끔 눈물을 흘린다.\n",
            "distil model:\t나는 가끔 눈물을 흘린다. \n",
            "tiny distil:\t나는 가끔 눈물을 흘린다.\n",
            "--------------------------------------------------\n",
            "원문: ㅇㅣ게 ㄱㅔ임이냐\n",
            "baseline:\t이게 게임이냐?\n",
            "distil model:\t이게 게임이냐? \n",
            "tiny distil:\t이게 게임이냐?\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print('-' * 50)\n",
        "for text in text_lt:\n",
        "    print('원문: ' + text)\n",
        "    for name, pipe in [('baseline', baseline_pipe), ('distil model', distil_pipe), ('tiny distil', tiny_distil_pipe)]:\n",
        "        result = pipe(text)\n",
        "        output_text = result[0]['generated_text']\n",
        "        print(f'{name}:\\t{output_text}')\n",
        "    print('-' * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGfsXiuRzWoQ",
        "outputId": "390e35de-1b34-4e58-c15a-d41d967b41cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_834/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2492022486.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_834/2492022486.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'tokenized_dataset'</span> is not defined\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_834/\u001b[0m\u001b[1;33m2492022486.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_834/2492022486.py'\u001b[0m                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'tokenized_dataset'\u001b[0m is not defined\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testset = tokenized_dataset['test'].with_format(\"torch\", device=device)\n",
        "test_sample = testset.shuffle().select(range(1))\n",
        "output = generate_from_data(baseline_model, tokenizer, test_sample)\n",
        "\n",
        "input_data = dict()\n",
        "input_data['input_ids'] = test_sample['input_ids']\n",
        "input_data['attention_mask'] = test_sample['attention_mask']\n",
        "distil_output = generate_seq(distil_model, tokenizer, input_data)\n",
        "tiny_distil_output = generate_seq(tiny_distil_model, tokenizer, input_data)\n",
        "quantized_distil_output = generate_seq(quantized_distil_model, tokenizer, input_data)\n",
        "quantized_tiny_distil_output = generate_seq(quantized_tiny_distil_model, tokenizer, input_data)\n",
        "\n",
        "print(output['input_text'], \n",
        "      'baseline: ' + output['generated_text'], \n",
        "      'distil: ' + distil_output,\n",
        "      'tiny_distil: ' + tiny_distil_output,\n",
        "      'quantized_distil: ' + quantized_distil_output,\n",
        "      'quantized_tiny_distil: ' + quantized_tiny_distil_output,\n",
        "      output['target_text'], \n",
        "      sep='\\n\\n'\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o-X7a1npzWoR",
        "outputId": "bd8a6f3f-77c2-4f98-a623-ca28e0526c37"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_834/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">4201288705.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_834/4201288705.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'testset'</span> is not defined\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_834/\u001b[0m\u001b[1;33m4201288705.py\u001b[0m:\u001b[94m20\u001b[0m in \u001b[92m<module>\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_834/4201288705.py'\u001b[0m                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'testset'\u001b[0m is not defined\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "bleu = evaluate.load('google_bleu')\n",
        "rouge = Rouge()\n",
        "result_df_dict = dict()\n",
        "model_lt = [\n",
        "    ('distil', distil_model), \n",
        "    ('tiny_distil', tiny_distil_model), \n",
        "    ('baseline', baseline_model), \n",
        "    ('quantized_distil', quantized_distil_model), \n",
        "    ('quantized_tiny_distil', quantized_tiny_distil_model),\n",
        "]\n",
        "\n",
        "performance_dict = dict()\n",
        "\n",
        "for name, model in model_lt:\n",
        "    accuracy_lt = []\n",
        "    bleu_score_lt = []\n",
        "    rouge_score_lt = []\n",
        "\n",
        "    start = timeit.default_timer()\n",
        "    for example in tqdm(testset.shuffle().select(range(4000))):\n",
        "        data = dict()\n",
        "        for key in example:\n",
        "            data[key] = example[key].unsqueeze(0)\n",
        "        output = generate_from_data(model, tokenizer, data)\n",
        "        generated_text = output['generated_text']\n",
        "        target_text = output['target_text']\n",
        "\n",
        "        try:\n",
        "            #accuracy_score = accuracy.compute(predictions=generated_text, references=target_text, tokenizer=tokenizer)\n",
        "            #bleu_score = bleu.compute(predictions=generated_text, references=target_text, tokenizer=tokenizer)\n",
        "            bleu_score = sentence_bleu([target_text], generated_text, smoothing_function=SmoothingFunction().method1)\n",
        "            rouge_score = rouge.get_scores(generated_text, target_text)[0]['rouge-2']['f']\n",
        "            #rouge_score = rouge.compute(predictions=generated_text, references=target_text)\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "        #accuracy_lt.append(accuracy_score)\n",
        "        bleu_score_lt.append(bleu_score)\n",
        "        rouge_score_lt.append(rouge_score)\n",
        "    end = timeit.default_timer()\n",
        "\n",
        "    bleu_score_series = pd.Series(bleu_score_lt)\n",
        "    rouge_score_series = pd.Series(rouge_score_lt)\n",
        "    print('BLEU: ' + str(bleu_score_series.mean()), \n",
        "          'ROUGE: ' + str(rouge_score_series.mean()), \n",
        "          'Time: ' + str(end - start), \n",
        "          sep='\\t'\n",
        "          )\n",
        "    result_df = pd.concat([bleu_score_series, rouge_score_series], axis=1)\n",
        "    result_df.columns = ['BLEU-2', 'ROUGE-2 F1']\n",
        "    result_df_dict[name] = result_df\n",
        "    performance_dict[name] = end - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sxKA-uq7zWoS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "distil\n",
            "distil:\t495559872\n",
            "tiny_distil\n",
            "tiny_distil:\t495559872\n",
            "baseline\n",
            "baseline:\t495559872\n",
            "quantized_distil\n",
            "quantized_distil:\t240849504\n",
            "quantized_tiny_distil\n",
            "quantized_tiny_distil:\t240849504\n"
          ]
        }
      ],
      "source": [
        "for name, model in model_lt:\n",
        "    print(name)\n",
        "    mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
        "    mem_bufs = sum([buf.nelement()*buf.element_size() for buf in model.buffers()])\n",
        "    mem = mem_params + mem_bufs\n",
        "\n",
        "    print(name + ':', mem, sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YWoEPuRVMoo2",
        "outputId": "58407fe2-36dc-486e-95d1-b57e9c58697e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_834/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3459465443.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_834/3459465443.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'distil'</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_834/\u001b[0m\u001b[1;33m3459465443.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_834/3459465443.py'\u001b[0m                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'distil'\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result_df_dict['distil']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zrHUq00ENKK_",
        "outputId": "8124a0ca-1fd2-468d-e3d4-c5ad1890f524"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_834/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1203489995.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_834/1203489995.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'baseline'</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_834/\u001b[0m\u001b[1;33m1203489995.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_834/1203489995.py'\u001b[0m                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'baseline'\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result_df_dict['baseline']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50OUgJ2yNYVy",
        "outputId": "c981ff6f-7399-49f0-b7a5-b2c9b2ffe670"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys([])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_df_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6e-_i67zWoT",
        "outputId": "bf7c8e6c-369f-4475-b425-462cb9e6663c"
      },
      "outputs": [],
      "source": [
        "for name, result_df in result_df_dict.items():\n",
        "    print(name)\n",
        "    result_df.to_json(f'drive/MyDrive/projects/KoGrammar/result-data/{name}-test-result.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YmCE6lRhzWoT"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABMkAAAGyCAYAAAD+jZMxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlnUlEQVR4nO3dbWyd5XkH8Mt28DGo2IRlcV5mmkFHaQskNCGeoQhRebUESpcPUzOokiziZbQZorG2khCIS2njjAGKVEIjUhj9UJa0CFDVRGHUa1RRPEVNYomOBEQDTVbVJlmHnYU2JvazDxWmJ8cOHMfHb/fvJ50PeXI/Pte5ZT9/6e/H55RlWZYFAAAAACSsfKwHAAAAAICxpiQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlFl2Q//elPY9GiRTFr1qwoKyuL55577gPP2bVrV3z605+OXC4XH/vYx+LJJ58cxqgApEDOAFBKcgaAoRRdkh0/fjzmzp0bmzZt+lDr33jjjbjhhhviuuuui46OjvjKV74St9xySzz//PNFDwvA5CdnACglOQPAUMqyLMuGfXJZWTz77LOxePHiIdfcddddsX379vjFL34xcOxv//Zv4+23346dO3cO96kBSICcAaCU5AwAf2xKqZ+gvb09Ghsb8441NTXFV77ylSHPOXHiRJw4cWLg3/39/fHb3/42/uRP/iTKyspKNSpAMrIsi2PHjsWsWbOivHxivz2lnAEYf+SMnAEopVLlTMlLss7Ozqitrc07VltbGz09PfG73/0uzj777IJzWltb47777iv1aADJO3z4cPzZn/3ZWI9xRuQMwPglZwAopZHOmZKXZMOxZs2aaG5uHvh3d3d3XHDBBXH48OGorq4ew8kAJoeenp6oq6uLc889d6xHGRNyBqC05IycASilUuVMyUuyGTNmRFdXV96xrq6uqK6uHvS3LhERuVwucrlcwfHq6mqhAjCCJsOffMgZgPFLzuSTMwAja6RzpuRvENDQ0BBtbW15x1544YVoaGgo9VMDkAA5A0ApyRmAdBRdkv3f//1fdHR0REdHR0T84SOROzo64tChQxHxh1uLly1bNrD+9ttvj4MHD8ZXv/rVOHDgQDz66KPx/e9/P1atWjUyrwCASUXOAFBKcgaAoRRdkv385z+PK664Iq644oqIiGhubo4rrrgi1q1bFxERv/nNbwYCJiLiz//8z2P79u3xwgsvxNy5c+Ohhx6K73znO9HU1DRCLwGAyUTOAFBKcgaAoZRlWZaN9RAfpKenJ2pqaqK7u9vf8AOMANfVfPYDYGS5ruazHwAjq1TX1ZK/JxkAAAAAjHdKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSpyQDAAAAIHlKMgAAAACSN6ySbNOmTTFnzpyoqqqK+vr62L1792nXb9y4MT7+8Y/H2WefHXV1dbFq1ar4/e9/P6yBAZj85AwApSRnABhM0SXZtm3borm5OVpaWmLv3r0xd+7caGpqirfeemvQ9U899VSsXr06WlpaYv/+/fH444/Htm3b4u677z7j4QGYfOQMAKUkZwAYStEl2cMPPxy33nprrFixIj75yU/G5s2b45xzzoknnnhi0PUvvfRSXH311XHTTTfFnDlz4nOf+1zceOONH/jbGgDSJGcAKCU5A8BQiirJent7Y8+ePdHY2Pj+Fygvj8bGxmhvbx/0nKuuuir27NkzECIHDx6MHTt2xPXXXz/k85w4cSJ6enryHgBMfnIGgFKSMwCczpRiFh89ejT6+vqitrY273htbW0cOHBg0HNuuummOHr0aHzmM5+JLMvi5MmTcfvtt5/29uTW1ta47777ihkNgElAzgBQSnIGgNMp+adb7tq1K9avXx+PPvpo7N27N5555pnYvn173H///UOes2bNmuju7h54HD58uNRjAjBByRkASknOAKSjqDvJpk2bFhUVFdHV1ZV3vKurK2bMmDHoOffee28sXbo0brnlloiIuOyyy+L48eNx2223xdq1a6O8vLCny+VykcvlihkNgElAzgBQSnIGgNMp6k6yysrKmD9/frS1tQ0c6+/vj7a2tmhoaBj0nHfeeacgOCoqKiIiIsuyYucFYBKTMwCUkpwB4HSKupMsIqK5uTmWL18eCxYsiIULF8bGjRvj+PHjsWLFioiIWLZsWcyePTtaW1sjImLRokXx8MMPxxVXXBH19fXx+uuvx7333huLFi0aCBcAeI+cAaCU5AwAQym6JFuyZEkcOXIk1q1bF52dnTFv3rzYuXPnwJtfHjp0KO83Lffcc0+UlZXFPffcE7/+9a/jT//0T2PRokXxzW9+c+ReBQCThpwBoJTkDABDKcsmwD3CPT09UVNTE93d3VFdXT3W4wBMeK6r+ewHwMhyXc1nPwBGVqmuqyX/dEsAAAAAGO+UZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkT0kGAAAAQPKUZAAAAAAkb1gl2aZNm2LOnDlRVVUV9fX1sXv37tOuf/vtt2PlypUxc+bMyOVycfHFF8eOHTuGNTAAk5+cAaCU5AwAg5lS7Anbtm2L5ubm2Lx5c9TX18fGjRujqakpXn311Zg+fXrB+t7e3virv/qrmD59ejz99NMxe/bs+NWvfhXnnXfeSMwPwCQjZwAoJTkDwFDKsizLijmhvr4+rrzyynjkkUciIqK/vz/q6urijjvuiNWrVxes37x5c/zLv/xLHDhwIM4666xhDdnT0xM1NTXR3d0d1dXVw/oaALxvPF9X5QzAxDeer6tyBmDiK9V1tag/t+zt7Y09e/ZEY2Pj+1+gvDwaGxujvb190HN++MMfRkNDQ6xcuTJqa2vj0ksvjfXr10dfX9+Qz3PixIno6enJewAw+ckZAEpJzgBwOkWVZEePHo2+vr6ora3NO15bWxudnZ2DnnPw4MF4+umno6+vL3bs2BH33ntvPPTQQ/GNb3xjyOdpbW2NmpqagUddXV0xYwIwQckZAEpJzgBwOiX/dMv+/v6YPn16PPbYYzF//vxYsmRJrF27NjZv3jzkOWvWrInu7u6Bx+HDh0s9JgATlJwBoJTkDEA6inrj/mnTpkVFRUV0dXXlHe/q6ooZM2YMes7MmTPjrLPOioqKioFjn/jEJ6KzszN6e3ujsrKy4JxcLhe5XK6Y0QCYBOQMAKUkZwA4naLuJKusrIz58+dHW1vbwLH+/v5oa2uLhoaGQc+5+uqr4/XXX4/+/v6BY6+99lrMnDlz0EABIF1yBoBSkjMAnE7Rf27Z3NwcW7Zsie9+97uxf//++NKXvhTHjx+PFStWRETEsmXLYs2aNQPrv/SlL8Vvf/vbuPPOO+O1116L7du3x/r162PlypUj9yoAmDTkDAClJGcAGEpRf24ZEbFkyZI4cuRIrFu3Ljo7O2PevHmxc+fOgTe/PHToUJSXv9+91dXVxfPPPx+rVq2Kyy+/PGbPnh133nln3HXXXSP3KgCYNOQMAKUkZwAYSlmWZdlYD/FBenp6oqamJrq7u6O6unqsxwGY8FxX89kPgJHluprPfgCMrFJdV0v+6ZYAAAAAMN4pyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABInpIMAAAAgOQpyQAAAABI3rBKsk2bNsWcOXOiqqoq6uvrY/fu3R/qvK1bt0ZZWVksXrx4OE8LQCLkDAClJmsAOFXRJdm2bduiubk5WlpaYu/evTF37txoamqKt95667Tnvfnmm/GP//iPcc011wx7WAAmPzkDQKnJGgAGU3RJ9vDDD8ett94aK1asiE9+8pOxefPmOOecc+KJJ54Y8py+vr744he/GPfdd19ceOGFZzQwAJObnAGg1GQNAIMpqiTr7e2NPXv2RGNj4/tfoLw8Ghsbo729fcjzvv71r8f06dPj5ptv/lDPc+LEiejp6cl7ADD5yRkASm00skbOAExMRZVkR48ejb6+vqitrc07XltbG52dnYOe8+KLL8bjjz8eW7Zs+dDP09raGjU1NQOPurq6YsYEYIKSMwCU2mhkjZwBmJhK+umWx44di6VLl8aWLVti2rRpH/q8NWvWRHd398Dj8OHDJZwSgIlKzgBQasPJGjkDMDFNKWbxtGnToqKiIrq6uvKOd3V1xYwZMwrW//KXv4w333wzFi1aNHCsv7//D088ZUq8+uqrcdFFFxWcl8vlIpfLFTMaAJOAnAGg1EYja+QMwMRU1J1klZWVMX/+/Ghraxs41t/fH21tbdHQ0FCw/pJLLomXX345Ojo6Bh6f//zn47rrrouOjg63HQOQR84AUGqyBoChFHUnWUREc3NzLF++PBYsWBALFy6MjRs3xvHjx2PFihUREbFs2bKYPXt2tLa2RlVVVVx66aV555933nkREQXHASBCzgBQerIGgMEUXZItWbIkjhw5EuvWrYvOzs6YN29e7Ny5c+CNLw8dOhTl5SV9qzMAJjE5A0CpyRoABlOWZVk21kN8kJ6enqipqYnu7u6orq4e63EAJjzX1Xz2A2Bkua7msx8AI6tU11W/HgEAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJKnJAMAAAAgeUoyAAAAAJI3rJJs06ZNMWfOnKiqqor6+vrYvXv3kGu3bNkS11xzTUydOjWmTp0ajY2Np10PAHIGgFKTNQCcquiSbNu2bdHc3BwtLS2xd+/emDt3bjQ1NcVbb7016Ppdu3bFjTfeGD/5yU+ivb096urq4nOf+1z8+te/PuPhAZh85AwApSZrABhMWZZlWTEn1NfXx5VXXhmPPPJIRET09/dHXV1d3HHHHbF69eoPPL+vry+mTp0ajzzySCxbtuxDPWdPT0/U1NREd3d3VFdXFzMuAIMYz9dVOQMw8Y336+poZ8143w+AiaZU19Wi7iTr7e2NPXv2RGNj4/tfoLw8Ghsbo729/UN9jXfeeSfefffdOP/884dcc+LEiejp6cl7ADD5yRkASm00skbOAExMRZVkR48ejb6+vqitrc07XltbG52dnR/qa9x1110xa9asvFA6VWtra9TU1Aw86urqihkTgAlKzgBQaqORNXIGYGIa1U+33LBhQ2zdujWeffbZqKqqGnLdmjVroru7e+Bx+PDhUZwSgIlKzgBQah8ma+QMwMQ0pZjF06ZNi4qKiujq6so73tXVFTNmzDjtuQ8++GBs2LAhfvzjH8fll19+2rW5XC5yuVwxowEwCcgZAEptNLJGzgBMTEXdSVZZWRnz58+Ptra2gWP9/f3R1tYWDQ0NQ573wAMPxP333x87d+6MBQsWDH9aACY1OQNAqckaAIZS1J1kERHNzc2xfPnyWLBgQSxcuDA2btwYx48fjxUrVkRExLJly2L27NnR2toaERH//M//HOvWrYunnnoq5syZM/B3/h/5yEfiIx/5yAi+FAAmAzkDQKnJGgAGU3RJtmTJkjhy5EisW7cuOjs7Y968ebFz586BN748dOhQlJe/f4Pat7/97ejt7Y2/+Zu/yfs6LS0t8bWvfe3Mpgdg0pEzAJSarAFgMGVZlmVjPcQH6enpiZqamuju7o7q6uqxHgdgwnNdzWc/AEaW62o++wEwskp1XR3VT7cEAAAAgPFISQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8pRkAAAAACRPSQYAAABA8oZVkm3atCnmzJkTVVVVUV9fH7t37z7t+h/84AdxySWXRFVVVVx22WWxY8eOYQ0LQBrkDAClJmsAOFXRJdm2bduiubk5WlpaYu/evTF37txoamqKt956a9D1L730Utx4441x8803x759+2Lx4sWxePHi+MUvfnHGwwMw+cgZAEpN1gAwmLIsy7JiTqivr48rr7wyHnnkkYiI6O/vj7q6urjjjjti9erVBeuXLFkSx48fjx/96EcDx/7yL/8y5s2bF5s3b/5Qz9nT0xM1NTXR3d0d1dXVxYwLwCDG83VVzgBMfOP9ujraWTPe9wNgoinVdXVKMYt7e3tjz549sWbNmoFj5eXl0djYGO3t7YOe097eHs3NzXnHmpqa4rnnnhvyeU6cOBEnTpwY+Hd3d3dE/GETADhz711Pi/w9ScnJGYDJYbzmTMToZI2cASitUuVMUSXZ0aNHo6+vL2pra/OO19bWxoEDBwY9p7Ozc9D1nZ2dQz5Pa2tr3HfffQXH6+rqihkXgA/wP//zP1FTUzPWYwyQMwCTy3jLmYjRyRo5AzA6RjpniirJRsuaNWvyflPz9ttvx0c/+tE4dOjQuAvZsdDT0xN1dXVx+PBht2uH/RiMPclnPwp1d3fHBRdcEOeff/5YjzIm5Mzp+ZkpZE/y2Y9C9iSfnJEzH8TPTD77kc9+FLIn+UqVM0WVZNOmTYuKioro6urKO97V1RUzZswY9JwZM2YUtT4iIpfLRS6XKzheU1Pjm+GPVFdX248/Yj8K2ZN89qNQefmwPuS4ZOTM+OJnppA9yWc/CtmTfOMtZyJGJ2vkzIfnZyaf/chnPwrZk3wjnTNFfbXKysqYP39+tLW1DRzr7++Ptra2aGhoGPSchoaGvPURES+88MKQ6wFIl5wBoNRkDQBDKfrPLZubm2P58uWxYMGCWLhwYWzcuDGOHz8eK1asiIiIZcuWxezZs6O1tTUiIu6888649tpr46GHHoobbrghtm7dGj//+c/jscceG9lXAsCkIGcAKDVZA8Bgii7JlixZEkeOHIl169ZFZ2dnzJs3L3bu3DnwRpaHDh3Ku93tqquuiqeeeiruueeeuPvuu+Mv/uIv4rnnnotLL730Qz9nLpeLlpaWQW9ZTpH9yGc/CtmTfPaj0HjeEzkz9uxHIXuSz34Usif5xvt+jHbWjPf9GAv2JJ/9yGc/CtmTfKXaj7JsPH4uMwAAAACMovH3TpoAAAAAMMqUZAAAAAAkT0kGAAAAQPKUZAAAAAAkb9yUZJs2bYo5c+ZEVVVV1NfXx+7du0+7/gc/+EFccsklUVVVFZdddlns2LFjlCYdHcXsx5YtW+Kaa66JqVOnxtSpU6OxsfED92+iKfb74z1bt26NsrKyWLx4cWkHHAPF7snbb78dK1eujJkzZ0Yul4uLL754Uv3cFLsfGzdujI9//ONx9tlnR11dXaxatSp+//vfj9K0pfXTn/40Fi1aFLNmzYqysrJ47rnnPvCcXbt2xac//enI5XLxsY99LJ588smSzzna5Ew+OVNI1uSTM/nkzPvkzODkTCFZk0/O5JMzhWTN+8Ysa7JxYOvWrVllZWX2xBNPZP/1X/+V3Xrrrdl5552XdXV1Dbr+Zz/7WVZRUZE98MAD2SuvvJLdc8892VlnnZW9/PLLozx5aRS7HzfddFO2adOmbN++fdn+/fuzv/u7v8tqamqy//7v/x7lyUuj2P14zxtvvJHNnj07u+aaa7K//uu/Hp1hR0mxe3LixIlswYIF2fXXX5+9+OKL2RtvvJHt2rUr6+joGOXJS6PY/fje976X5XK57Hvf+172xhtvZM8//3w2c+bMbNWqVaM8eWns2LEjW7t2bfbMM89kEZE9++yzp11/8ODB7Jxzzsmam5uzV155JfvWt76VVVRUZDt37hydgUeBnMknZwrJmnxyJp+cySdnCsmZQrImn5zJJ2cKyZp8Y5U146IkW7hwYbZy5cqBf/f19WWzZs3KWltbB13/hS98IbvhhhvyjtXX12d///d/X9I5R0ux+3GqkydPZueee2723e9+t1Qjjqrh7MfJkyezq666KvvOd76TLV++fFIFSpYVvyff/va3swsvvDDr7e0drRFHVbH7sXLlyuyzn/1s3rHm5ubs6quvLumcY+HDBMpXv/rV7FOf+lTesSVLlmRNTU0lnGx0yZl8cqaQrMknZ/LJmaHJmT+QM4VkTT45k0/OFJI1QxvNrBnzP7fs7e2NPXv2RGNj48Cx8vLyaGxsjPb29kHPaW9vz1sfEdHU1DTk+olkOPtxqnfeeSfefffdOP/880s15qgZ7n58/etfj+nTp8fNN988GmOOquHsyQ9/+MNoaGiIlStXRm1tbVx66aWxfv366OvrG62xS2Y4+3HVVVfFnj17Bm5fPnjwYOzYsSOuv/76UZl5vJnM19QIOXMqOVNI1uSTM/nkzJmbzNfUCDkzGFmTT87kkzOFZM2ZG6nr6pSRHGo4jh49Gn19fVFbW5t3vLa2Ng4cODDoOZ2dnYOu7+zsLNmco2U4+3Gqu+66K2bNmlXwDTIRDWc/XnzxxXj88cejo6NjFCYcfcPZk4MHD8Z//Md/xBe/+MXYsWNHvP766/HlL3853n333WhpaRmNsUtmOPtx0003xdGjR+Mzn/lMZFkWJ0+ejNtvvz3uvvvu0Rh53BnqmtrT0xO/+93v4uyzzx6jyUaGnMknZwrJmnxyJp+cOXNyptBkzpkIWXMqOZNPzhSSNWdupLJmzO8kY2Rt2LAhtm7dGs8++2xUVVWN9Tij7tixY7F06dLYsmVLTJs2bazHGTf6+/tj+vTp8dhjj8X8+fNjyZIlsXbt2ti8efNYjzYmdu3aFevXr49HH3009u7dG88880xs37497r///rEeDca91HMmQtYMRs7kkzNwZlLPGjlTSM4UkjWlMeZ3kk2bNi0qKiqiq6sr73hXV1fMmDFj0HNmzJhR1PqJZDj78Z4HH3wwNmzYED/+8Y/j8ssvL+WYo6bY/fjlL38Zb775ZixatGjgWH9/f0RETJkyJV599dW46KKLSjt0iQ3ne2TmzJlx1llnRUVFxcCxT3ziE9HZ2Rm9vb1RWVlZ0plLaTj7ce+998bSpUvjlltuiYiIyy67LI4fPx633XZbrF27NsrL0/r9wVDX1Orq6gn/2/0IOXMqOVNI1uSTM/nkzJmTM4Umc85EyJpTyZl8cqaQrDlzI5U1Y75rlZWVMX/+/Ghraxs41t/fH21tbdHQ0DDoOQ0NDXnrIyJeeOGFIddPJMPZj4iIBx54IO6///7YuXNnLFiwYDRGHRXF7scll1wSL7/8cnR0dAw8Pv/5z8d1110XHR0dUVdXN5rjl8RwvkeuvvrqeP311wfCNSLitddei5kzZ074QBnOfrzzzjsFofFe4P7hfSHTMpmvqRFy5lRyppCsySdn8smZMzeZr6kRcmYwsiafnMknZwrJmjM3YtfVot7mv0S2bt2a5XK57Mknn8xeeeWV7LbbbsvOO++8rLOzM8uyLFu6dGm2evXqgfU/+9nPsilTpmQPPvhgtn///qylpWVSfWRysfuxYcOGrLKyMnv66aez3/zmNwOPY8eOjdVLGFHF7sepJtsnwWRZ8Xty6NCh7Nxzz83+4R/+IXv11VezH/3oR9n06dOzb3zjG2P1EkZUsfvR0tKSnXvuudm//du/ZQcPHsz+/d//PbvooouyL3zhC2P1EkbUsWPHsn379mX79u3LIiJ7+OGHs3379mW/+tWvsizLstWrV2dLly4dWP/exyX/0z/9U7Z///5s06ZNw/q45PFMzuSTM4VkTT45k0/O5JMzheRMIVmTT87kkzOFZE2+scqacVGSZVmWfetb38ouuOCCrLKyMlu4cGH2n//5nwP/d+2112bLly/PW//9738/u/jii7PKysrsU5/6VLZ9+/ZRnri0itmPj370o1lEFDxaWlpGf/ASKfb7449NtkB5T7F78tJLL2X19fVZLpfLLrzwwuyb3/xmdvLkyVGeunSK2Y933303+9rXvpZddNFFWVVVVVZXV5d9+ctfzv73f/939AcvgZ/85CeDXhPe24Ply5dn1157bcE58+bNyyorK7MLL7ww+9d//ddRn7vU5Ew+OVNI1uSTM/nkzPvkzODkTCFZk0/O5JMzhWTN+8Yqa8qyLMH78AAAAADgj4z5e5IBAAAAwFhTkgEAAACQPCUZAAAAAMlTkgEAAACQPCUZAAAAAMlTkgEAAACQPCUZAAAAAMlTkgEAAACQPCUZAAAAAMlTkgEAAACQPCUZAAAAAMlTkgEAAACQvP8Ho+zDKdd2Bn8AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 5), ncols=3, nrows=1)\n",
        "for i, (name, result_df) in enumerate(result_df_dict.items()):\n",
        "    sns.kdeplot(data=result_df, \n",
        "                fill=True, \n",
        "                palette=\"crest\", \n",
        "                common_grid=True, \n",
        "                cut=1, \n",
        "                ax=ax[i],\n",
        "                )\n",
        "    \n",
        "    ax[i].set_title(name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
